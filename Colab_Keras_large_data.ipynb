{"cells":[{"cell_type":"markdown","metadata":{"id":"KIR1zP0dvAOa"},"source":["# Hate Speech Detection Model (w/ Large, random data)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8848,"status":"ok","timestamp":1655469104449,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"CJ4koSJ1xbLr","outputId":"f4e79e56-9767-4661-f993-27e1d3eb9f8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'CS376_Final_Project'...\n","remote: Enumerating objects: 372, done.\u001b[K\n","remote: Counting objects: 100% (28/28), done.\u001b[K\n","remote: Compressing objects: 100% (22/22), done.\u001b[K\n","remote: Total 372 (delta 2), reused 22 (delta 2), pack-reused 344\u001b[K\n","Receiving objects: 100% (372/372), 154.62 MiB | 26.53 MiB/s, done.\n","Resolving deltas: 100% (167/167), done.\n","Checking out files: 100% (83/83), done.\n"]}],"source":["!git clone https://github.com/joseph1723/CS376_Final_Project.git"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"YHWRrOYpuyPV","executionInfo":{"status":"ok","timestamp":1655469114076,"user_tz":-540,"elapsed":9645,"user":{"displayName":"김동근","userId":"08688198781637620604"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import math\n","from keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"CjInRHDwyuUU","executionInfo":{"status":"ok","timestamp":1655469114078,"user_tz":-540,"elapsed":42,"user":{"displayName":"김동근","userId":"08688198781637620604"}}},"outputs":[],"source":["class TestDataset(Dataset) :\n","  #Dataset - English/typo-added/labeled\n","  def __init__(self, df) :\n","    self.df = df\n","  \n","  def __len__(self) :\n","    return len(self.df)\n","  \n","  def __getitem__(self, idx):\n","    text = self.df.iloc[idx, 0]\n","    item = self.df.iloc[idx, 1]\n","    return text, item"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1655469114080,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"3AaP5n2IMsMg","outputId":"d8b12a0e-583b-4ed6-83f0-9fc05b3ba2a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                    text  label\n","0      just called this bitch a cum dumpster on the t...      0\n","1      This dress looks fucking bad on me and I look ...      1\n","2      If they people don't react well, to you coming...      1\n","3      \"There is no correlation between black populat...      0\n","4                Fuck yeah, I would kill for some fries.      1\n","...                                                  ...    ...\n","10419  would you like to be called brown? Then stop u...      1\n","10420  i hate being a lesbian living in this country,...      1\n","10421  The curfew you wanted but now you don't,  make...      1\n","10422  I love how HE has to come on to this forum, ch...      0\n","10423  would you like to be called a queer? Then stop...      1\n","\n","[10424 rows x 2 columns]\n"]}],"source":["train_rate, test_rate = 0.9, 0.05\n","total_df = pd.read_csv('/content/CS376_Final_Project/augmented_data/Dataset_aug_complex_10424_original.csv', sep=',')\n","total_df.dropna(inplace=True)\n","total_df = total_df[[\"text\", \"label\"]]\n","total_df[\"label\"] = [1 if i == \"nothate\" else 0 for i in total_df[\"label\"]]\n","print(total_df)"]},{"cell_type":"markdown","metadata":{"id":"7DXbBmkz3XJ9"},"source":["LSTM 데이타 전처리"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"L6Xrr5bD4w85","executionInfo":{"status":"ok","timestamp":1655469114082,"user_tz":-540,"elapsed":31,"user":{"displayName":"김동근","userId":"08688198781637620604"}}},"outputs":[],"source":["total_dataset = TestDataset(total_df)\n","total_loader = DataLoader(total_dataset, batch_size=1, shuffle=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":545,"status":"ok","timestamp":1655469114598,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"l-Z5G2AhlqzT","outputId":"2984596b-5ff8-41f9-b59e-c6fbc4ce54e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'textClassifier'...\n","remote: Enumerating objects: 56, done.\u001b[K\n","remote: Counting objects: 100% (1/1), done.\u001b[K\n","remote: Total 56 (delta 0), reused 1 (delta 0), pack-reused 55\u001b[K\n","Unpacking objects: 100% (56/56), done.\n"]}],"source":["# clone the repo\n","!git clone https://github.com/richliao/textClassifier.git\n","# install Dependent library"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42955,"status":"ok","timestamp":1655469157536,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"vFoIN0a3mICT","outputId":"bc7618b9-6eb9-4309-b32b-b91144306e93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting backports.weakref==1.0.post1\n","  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n","Requirement already satisfied: beautifulsoup4==4.6.3 in /usr/local/lib/python3.7/dist-packages (from -r ./textClassifier/req.txt (line 2)) (4.6.3)\n","Collecting bleach==1.5.0\n","  Downloading bleach-1.5.0-py2.py3-none-any.whl (17 kB)\n","Requirement already satisfied: bs4==0.0.1 in /usr/local/lib/python3.7/dist-packages (from -r ./textClassifier/req.txt (line 4)) (0.0.1)\n","Collecting Cython==0.27.3\n","  Downloading Cython-0.27.3.tar.gz (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 8.9 MB/s \n","\u001b[?25hCollecting enum34==1.1.6\n","  Downloading enum34-1.1.6-py3-none-any.whl (12 kB)\n","Collecting funcsigs==1.0.2\n","  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n","Collecting h5py==2.7.1\n","  Downloading h5py-2.7.1.tar.gz (264 kB)\n","\u001b[K     |████████████████████████████████| 264 kB 69.1 MB/s \n","\u001b[?25hCollecting html5lib==0.9999999\n","  Downloading html5lib-0.9999999.tar.gz (889 kB)\n","\u001b[K     |████████████████████████████████| 889 kB 58.8 MB/s \n","\u001b[?25hCollecting Keras==2.0.8\n","  Downloading Keras-2.0.8-py2.py3-none-any.whl (276 kB)\n","\u001b[K     |████████████████████████████████| 276 kB 65.5 MB/s \n","\u001b[?25hCollecting laspy==1.5.0\n","  Downloading laspy-1.5.0-py3-none-any.whl (489 kB)\n","\u001b[K     |████████████████████████████████| 489 kB 58.9 MB/s \n","\u001b[?25hCollecting lda==1.0.5\n","  Downloading lda-1.0.5.tar.gz (303 kB)\n","\u001b[K     |████████████████████████████████| 303 kB 67.6 MB/s \n","\u001b[?25hCollecting Markdown==2.6.9\n","  Downloading Markdown-2.6.9.tar.gz (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 60.3 MB/s \n","\u001b[?25hCollecting mock==2.0.0\n","  Downloading mock-2.0.0-py2.py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 5.6 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 50.6 MB/s \n","\u001b[?25hCollecting numpy==1.13.3\n","  Downloading numpy-1.13.3.zip (5.0 MB)\n","\u001b[K     |████████████████████████████████| 5.0 MB 45.4 MB/s \n","\u001b[?25hCollecting olefile==0.44\n","  Downloading olefile-0.44.zip (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 1.9 MB/s \n","\u001b[?25hCollecting pandas==0.20.3\n","  Downloading pandas-0.20.3.tar.gz (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 31.5 MB/s \n","\u001b[?25hCollecting pbr==3.1.1\n","  Downloading pbr-3.1.1-py2.py3-none-any.whl (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 10.8 MB/s \n","\u001b[?25hCollecting Pillow==4.3.0\n","  Downloading Pillow-4.3.0.tar.gz (13.9 MB)\n","\u001b[K     |████████████████████████████████| 13.9 MB 28.7 MB/s \n","\u001b[?25hCollecting protobuf==3.4.0\n","  Downloading protobuf-3.4.0-py2.py3-none-any.whl (375 kB)\n","\u001b[K     |████████████████████████████████| 375 kB 72.3 MB/s \n","\u001b[?25hCollecting pypinyin==0.29.0\n","  Downloading pypinyin-0.29.0-py2.py3-none-any.whl (987 kB)\n","\u001b[K     |████████████████████████████████| 987 kB 62.1 MB/s \n","\u001b[?25hCollecting python-dateutil==2.6.1\n","  Downloading python_dateutil-2.6.1-py2.py3-none-any.whl (194 kB)\n","\u001b[K     |████████████████████████████████| 194 kB 73.5 MB/s \n","\u001b[?25hCollecting pytz==2017.2\n","  Downloading pytz-2017.2-py2.py3-none-any.whl (484 kB)\n","\u001b[K     |████████████████████████████████| 484 kB 66.6 MB/s \n","\u001b[?25hCollecting PyYAML==3.12\n","  Downloading PyYAML-3.12.zip (375 kB)\n","\u001b[K     |████████████████████████████████| 375 kB 58.6 MB/s \n","\u001b[?25hCollecting scikit-learn==0.19.1\n","  Downloading scikit-learn-0.19.1.tar.gz (9.5 MB)\n","\u001b[K     |████████████████████████████████| 9.5 MB 21.7 MB/s \n","\u001b[?25hCollecting scipy==0.19.1\n","  Downloading scipy-0.19.1.tar.gz (14.1 MB)\n","\u001b[K     |████████████████████████████████| 14.1 MB 27.1 MB/s \n","\u001b[?25hCollecting six==1.11.0\n","  Downloading six-1.11.0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from -r ./textClassifier/req.txt (line 29)) (0.0)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.3.0 (from versions: 1.13.1, 1.13.2, 1.14.0, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.0+zzzcolab20220506153740, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.4+zzzcolab20220516125453, 2.6.5, 2.6.5+zzzcolab20220523104206, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.0+zzzcolab20220506150900, 2.7.1, 2.7.2, 2.7.2+zzzcolab20220516114640, 2.7.3, 2.7.3+zzzcolab20220523111007, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.0+zzzcolab20220506162203, 2.8.1, 2.8.1+zzzcolab20220516111314, 2.8.1+zzzcolab20220518083849, 2.8.2, 2.8.2+zzzcolab20220523105045, 2.8.2+zzzcolab20220527125636, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for tensorflow==1.3.0\u001b[0m\n"]}],"source":["# !cd textClassifier\n","# !ls\n","# !pip install -r req.txt\n","!pip install -r ./textClassifier/req.txt"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3224,"status":"ok","timestamp":1655469160734,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"6GbH06wH27U3","outputId":"334f1a03-f6d3-4870-e063-bd8f3f8f8322"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n","Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159853,"status":"ok","timestamp":1655469320567,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"SHzEjw4moKBn","outputId":"129e6fd2-60d8-4cbe-8998-7b94acabcad7"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-06-17 12:32:40--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2022-06-17 12:32:40--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2022-06-17 12:32:40--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.11MB/s    in 2m 39s  \n","\n","2022-06-17 12:35:20 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"]}],"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30946,"status":"ok","timestamp":1655469351418,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"FQLAP7ANoN1E","outputId":"247fcf6a-959f-4603-b17f-c71f09dd6e5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"]}],"source":["!unzip glove.6B.zip"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":689,"status":"ok","timestamp":1655469351984,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"0XAVNanDpBzX","outputId":"3b579568-f64a-43a9-a764-bd2684bbe271"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-06-17 12:35:50--  https://www.kaggle.com/c/word2vec-nlp-tutorial/download/labeledTrainData.tsv\n","Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n","Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /account/login?returnUrl=%2Fcompetitions%2Fword2vec-nlp-tutorial [following]\n","--2022-06-17 12:35:50--  https://www.kaggle.com/account/login?returnUrl=%2Fcompetitions%2Fword2vec-nlp-tutorial\n","Reusing existing connection to www.kaggle.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: ‘labeledTrainData.tsv’\n","\n","labeledTrainData.ts     [ <=>                ]   6.51K  --.-KB/s    in 0.004s  \n","\n","2022-06-17 12:35:51 (1.78 MB/s) - ‘labeledTrainData.tsv’ saved [6669]\n","\n"]}],"source":["!wget https://www.kaggle.com/c/word2vec-nlp-tutorial/download/labeledTrainData.tsv"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3106,"status":"ok","timestamp":1655469355075,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"lw_PaR6wodXY","outputId":"f90ad85c-725e-42d5-f025-46842d421baa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.30)\n"]}],"source":["!pip install --upgrade cython"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1413,"status":"ok","timestamp":1655469356418,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"fxOeDJSAnHfa","outputId":"7f3b8100-c1d6-43cd-ed2b-a6a27bb8ea2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.3.0 (from versions: 1.13.1, 1.13.2, 1.14.0, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.0+zzzcolab20220506153740, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.4+zzzcolab20220516125453, 2.6.5, 2.6.5+zzzcolab20220523104206, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.0+zzzcolab20220506150900, 2.7.1, 2.7.2, 2.7.2+zzzcolab20220516114640, 2.7.3, 2.7.3+zzzcolab20220523111007, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.0+zzzcolab20220506162203, 2.8.1, 2.8.1+zzzcolab20220516111314, 2.8.1+zzzcolab20220518083849, 2.8.2, 2.8.2+zzzcolab20220523105045, 2.8.2+zzzcolab20220527125636, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for tensorflow==1.3.0\u001b[0m\n"]}],"source":["!pip install --upgrade tensorflow==1.3.0"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70336,"status":"ok","timestamp":1655469426700,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"mbFHFHwKiqRB","outputId":"9456bd92-4478-4273-c16e-d6e71f0106ce"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n","  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"]},{"output_type":"stream","name":"stdout","text":["Total 400000 word vectors.\n","model fitting - attention Bi-LSTM network\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 54)]         0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 54, 100)      878500      ['input_1[0][0]']                \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, 54, 200)      160800      ['embedding[0][0]']              \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 1)]          0           []                               \n","                                                                                                  \n"," attention_layer (AttentionLaye  ((None, 200),       0           ['bidirectional[0][0]',          \n"," r)                              (None, 3),                       'input_2[0][0]']                \n","                                 (None, 54))                                                      \n","                                                                                                  \n"," dense (Dense)                  (None, 2)            402         ['attention_layer[0][0]']        \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,039,702\n","Trainable params: 1,039,702\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/500\n","167/167 [==============================] - 11s 18ms/step - loss: 0.6099 - acc: 0.6501 - val_loss: 0.5551 - val_acc: 0.6833\n","Epoch 2/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.4967 - acc: 0.7470 - val_loss: 0.4818 - val_acc: 0.7639\n","Epoch 3/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.3848 - acc: 0.8241 - val_loss: 0.4753 - val_acc: 0.7596\n","Epoch 4/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.2966 - acc: 0.8737 - val_loss: 0.4754 - val_acc: 0.7750\n","Epoch 5/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.2177 - acc: 0.9116 - val_loss: 0.5056 - val_acc: 0.7817\n","Epoch 6/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.1584 - acc: 0.9376 - val_loss: 0.6511 - val_acc: 0.7726\n","Epoch 7/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.1144 - acc: 0.9544 - val_loss: 0.7603 - val_acc: 0.7769\n","Epoch 8/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.0855 - acc: 0.9688 - val_loss: 0.8469 - val_acc: 0.7668\n","Epoch 9/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.0635 - acc: 0.9760 - val_loss: 0.8818 - val_acc: 0.7826\n","Epoch 10/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.0487 - acc: 0.9827 - val_loss: 0.9969 - val_acc: 0.7817\n","Epoch 11/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.0350 - acc: 0.9885 - val_loss: 1.1214 - val_acc: 0.7759\n","Epoch 12/500\n","167/167 [==============================] - 2s 12ms/step - loss: 0.0306 - acc: 0.9904 - val_loss: 1.1234 - val_acc: 0.7802\n","Epoch 13/500\n","167/167 [==============================] - 2s 13ms/step - loss: 0.0218 - acc: 0.9938 - val_loss: 1.3765 - val_acc: 0.7735\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f9d444f5390>"]},"metadata":{},"execution_count":14}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","import numpy as np\n","import pandas as pd\n","import sys, os, importlib, re, tensorflow.python.keras.engine\n","from collections import defaultdict\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils.np_utils import to_categorical\n","from keras.layers import Dense, Input, Embedding, Dropout, LSTM, Bidirectional, Embedding, Layer\n","from keras.models import Model\n","from keras import initializers\n","\n","os.environ['KERAS_BACKEND']='theano'\n","\n","#Parameters\n","MAX_SEQUENCE_LENGTH = 54\n","MAX_NB_WORDS = 20000\n","EMBEDDING_DIM = 100\n","VALIDATION_SPLIT = 0.2\n","\n","\n","texts = []\n","labels = []\n","valid_lengths = []\n","split_input = []\n","\n","for text, label in total_loader:\n","  texts.append(text[0])\n","  labels.append(label[0])\n","  valid_lengths.append(len(text[0].split(' ')))\n","  split_input.append(text[0].split(' '))\n","    \n","\n","tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n","tokenizer.fit_on_texts(texts)\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","word_index = tokenizer.word_index\n","\n","textseq = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding = 'post')\n","split = pad_sequences(split_input, maxlen = MAX_SEQUENCE_LENGTH, padding = 'post', dtype = object, value = '_PAD_')\n","\n","labels = to_categorical(np.asarray(labels))\n","\n","indices = np.arange(textseq.shape[0])\n","np.random.shuffle(indices)\n","\n","\n","valid_lengths = np.array(valid_lengths)\n","split = np.array(split)\n","textseq = textseq[indices]\n","labels = labels[indices]\n","valid_lens = valid_lengths[indices]\n","split = split[indices]\n","nb_validation_samples = int(VALIDATION_SPLIT * textseq.shape[0])\n","\n","\n","texts_for_print = np.array(texts)\n","texts_for_print = texts_for_print[indices]\n","\n","\n","x_train = textseq[:-nb_validation_samples]\n","y_train = labels[:-nb_validation_samples]\n","x_val = textseq[-nb_validation_samples:]\n","y_val = labels[-nb_validation_samples:]\n","vallen_train = valid_lens[:-nb_validation_samples]\n","vallen_val = valid_lens[-nb_validation_samples:]\n","\n","class AttentionLayer(Layer):\n","    def __init__(self, **kwargs):\n","        self.init = initializers.get('normal')\n","        super(AttentionLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape)==3\n","        self.W = self.init((input_shape[-1],))\n","        self.sm = tf.keras.layers.Softmax(axis = -1)\n","        super(AttentionLayer, self).build(input_shape)\n","\n","    def call(self, x, mask=None, splited_input = None, answer = None, batch_size = None):\n","        eij = K.tanh(K.squeeze(K.dot(x, K.expand_dims(self.W)), axis=-1))\n","        masking = np.array([range(x.shape[1])])<mask\n","        ai = self.sm(eij, masking)\n","        ai_result = tf.argsort(ai, direction = 'DESCENDING',)\n","        weights = ai/tf.expand_dims(K.sum(ai, axis = 1), 1)\n","        weighted_input = x*tf.expand_dims(weights,2)\n","        return K.sum(weighted_input, axis = 1), ai_result[:, :3], ai\n","\n","\n","GLOVE_DIR = \"./\"\n","embeddings_index = {}\n","f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","\n","print('Total %s word vectors.' % len(embeddings_index))\n","\n","\n","\n","embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","        \n","#Input Declartion\n","sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","valid_len_input = Input(shape = (1, ), dtype = 'int32')\n","\n","#Model structure\n","embedded_sequences = Embedding(len(word_index) + 1,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            input_length=MAX_SEQUENCE_LENGTH,\n","                            trainable=True)(sequence_input)\n","lstm_out = Bidirectional(LSTM(100, return_sequences=True))(embedded_sequences)\n","att_out, _, _ = AttentionLayer()(lstm_out, mask = valid_len_input)\n","preds = Dense(2, activation='softmax')(att_out)\n","#Early stopper\n","callback = tf.keras.callbacks.EarlyStopping(\n","    monitor=\"val_loss\",\n","    min_delta=0,\n","    patience=10,\n","    verbose=0,\n","    mode=\"auto\",\n","    baseline=None,\n","    restore_best_weights=False,\n",")\n","#Model Train\n","model = Model([sequence_input, valid_len_input], preds)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","print(\"model fitting - attention Bi-LSTM network\")\n","model.summary()\n","model.fit([x_train, vallen_train], y_train, validation_data=([x_val, vallen_val], y_val),\n","          batch_size = 50 , epochs = 500, callbacks=[callback])"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12111,"status":"ok","timestamp":1655469549343,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"G6ewjLYZ1EFo","outputId":"1ccff615-b268-460b-89a9-89cb026f6943"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as softmax_layer_call_fn, softmax_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ./model_save_check_large/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: ./model_save_check_large/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9dbfc1c690> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9db02c5150> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}],"source":["model.save('./model_save_check_large')"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":867,"status":"ok","timestamp":1655469609220,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"b9Gp8FTk1n50","outputId":"b4a1e91a-3508-4b19-e564-727ec4d14331"},"outputs":[{"output_type":"stream","name":"stdout","text":["updating: model_save_check_large/ (stored 0%)\n","updating: model_save_check_large/variables/ (stored 0%)\n","updating: model_save_check_large/variables/variables.data-00000-of-00001 (deflated 11%)\n","updating: model_save_check_large/variables/variables.index (deflated 66%)\n","updating: model_save_check_large/keras_metadata.pb (deflated 89%)\n","updating: model_save_check_large/saved_model.pb (deflated 90%)\n","updating: model_save_check_large/assets/ (stored 0%)\n"]}],"source":["!zip -r model_save_check_large.zip model_save_check_large"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1655469448712,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"Z0-sc0kPucSX","outputId":"fa2bc0df-d7c2-4a5d-8855-57185194d5a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  text  label\n","0    Any of those gas chambers still available? I w...      0\n","1    He will never propose to you, when you get old...      0\n","2    there is no difference between white women and...      0\n","3    The world would be so much better if we were d...      0\n","4    comparing maternity leave with paternity leave...      0\n","..                                                 ...    ...\n","395  I read an article where black men said it can ...      1\n","396  Honestly, I was pretty shocked to hear that sh...      1\n","397  I still believe all of that is because most of...      1\n","398  you can not come with us because you are weari...      1\n","399                               some men are abusers      1\n","\n","[400 rows x 2 columns]\n"]}],"source":["Test_uniform_df = pd.read_csv(\"/content/CS376_Final_Project/datasets/2020-12-31-DynamicallyGeneratedHateDataset-entries-v0.2.csv\",sep=',')\n","Test_uniform_df.dropna(inplace=True)\n","Test_uniform_df = Test_uniform_df[['text','label']]\n","Test_uniform_df_hate = Test_uniform_df.loc[Test_uniform_df['label'] == 'hate',:]\n","Test_uniform_df_nothate = Test_uniform_df.loc[Test_uniform_df['label'] == 'nothate',:]\n","Test_uniform_df = pd.concat([Test_uniform_df_hate[:200], Test_uniform_df_nothate[:200]], axis=0).reset_index(drop=True)\n","#Test_uniform_df = Test_uniform_df.sample(frac=1).reset_index(drop=True)\n","Test_uniform_df[\"label\"] = [1 if i == \"nothate\" else 0 for i in Test_uniform_df[\"label\"]]\n","\n","print(Test_uniform_df)\n","\n","texts_test = list(Test_uniform_df['text'])\n","results_True = list(Test_uniform_df['label'])"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1655469448713,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"_75E0C4vp5Zx"},"outputs":[],"source":["valid_lengths_test = []\n","split_input_test = []\n","for text in texts_test:\n","  valid_lengths_test.append(len(text.split(' '))) \n","  split_input_test.append(text.split(' '))\n","sequences_test = tokenizer.texts_to_sequences(texts_test)\n","\n","word_index = tokenizer.word_index\n","\n","data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH, padding = 'post')\n","split_test = pad_sequences(split_input_test, maxlen = MAX_SEQUENCE_LENGTH, padding = 'post', dtype = object, value = '_PAD_')\n","\n","indicess = np.arange(data_test.shape[0])\n","# np.random.shuffle(indices)\n","\n","valid_lengths_test = np.array(valid_lengths_test)\n","split_test = np.array(split_test)\n","textss = np.array(texts_test)\n","\n","x_test = data_test[:]\n","vallen_test = valid_lengths_test[:]"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":576,"status":"ok","timestamp":1655469449277,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"BfrNpUdaY8Lg","outputId":"714de232-7eb2-4404-ea9f-bb8caa67050c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n"," 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0\n"," 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1\n"," 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1\n"," 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1\n"," 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1\n"," 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n"," 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1\n"," 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n"," 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1]\n","['mix' 'with' 'blacks'] The world would be so much better if we were divided by colours - I don't want to mix with blacks [0.16159035 0.14122395 0.13311332]\n","['maternity' 'leave' 'is'] comparing maternity leave with paternity leave, it is sooooooo unfair [0.12405407 0.12294272 0.11362103]\n","['be' 'at' 'would'] Women think they're being edgy and cool by trying to embody the worst characteristics that they think they are manly so they can hate on men like us . These are the people doing research. fuck. Imagine no women at universities, would be reallly cool [0.08090749 0.07772867 0.06970507]\n","['munchers' 'are' 'pleasant'] Curry munchers are not pleasant to look at [0.15639214 0.15488544 0.15147592]\n","['irrelevant' 'women' 'are'] women are irrelevant [0.350373   0.32492048 0.3247065 ]\n","[\"don't\" 'them' 'like'] don't get me wrong I don't hate Indian people, but I definitely don't like them [0.17386065 0.15986776 0.14740594]\n","['like' 'did.' 'children.'] Women have no accountability. Absolutely zero. They never did. Women are just like children. [0.12282764 0.12198926 0.10823525]\n","['Asians' 'they' 'is'] The one good thing about Asians is they work hard [0.20774849 0.17175364 0.17056042]\n","[\"don't\" 'faggots' 'understand'] faggots don't understand shit [0.30559677 0.2519031  0.24822809]\n","['integrate' 'society' 'in'] I love the fact that Asian women don\u0018t even try to integrate in our society [0.13275728 0.11952058 0.09943467]\n","['come' 'will' 'along'] Calling women 'coackroaches' is fabulous! Such descriptive term - you stamp one out and another will come along [0.09786277 0.09354179 0.09273648]\n","['Shylock' 'a' 'with'] I could never be friends with a Shylock [0.35475382 0.2238874  0.11644115]\n","['tards' 'cancer' 'are'] tards are cancer [0.35323817 0.32905895 0.31770286]\n","['many' 'jews' 'too'] if the population wasn't cleansed during the holocaust there would be too many jews [0.21519506 0.17440015 0.1455008 ]\n","['gay' 'people' 'among'] We should ban public displays of affection among gay people [0.24087071 0.17643617 0.16879697]\n","['slaves' 'are' 'people'] black people are slaves [0.33405012 0.30447063 0.20099066]\n","['are' 'black' 'superior'] white people are superior to black people [0.1663746  0.16301289 0.15429166]\n","[\"aren't\" 'attractive' 'women'] Black women just aren't attractive [0.27065375 0.22329436 0.20974752]\n","['tranni3s' 'be' \"shouldn't\"] tranni3s shouldn't be allowed to adopt [0.21564496 0.20542978 0.17564677]\n","['women' 'pregnant' 'disability'] pregnant women have a disability [0.24260536 0.197672   0.1962737 ]\n","['women' 'repulsive' 'are'] Barren women are repulsive [0.32818815 0.26438484 0.26172435]\n","['Chinese' 'person' 'a'] I wouldn't eat food that has been touched by a Chinese person [0.22563875 0.17948543 0.16133724]\n","['government.' 'money' 'more'] Wtf are you gay? Why would you whine and complain about some bimbo. Even ig she has kids with a guy does not mean she won't cheat on him lol. I can guarantee you that. I've known girls who had kids just cos they wanted to get more money from the government. [0.04278476 0.04000775 0.03725707]\n","['on' 'face' 'their'] i love it when chicks try to be funny, they fall flat on their face [0.12188692 0.108768   0.10676757]\n","['want' 'also' 'poverty;'] To a large extent white moving to the suburbs is driven by people wanting to live among other whites. I understand this isn't intended to create white enclaves as such, but it has turned out that way. Most suburbs are majority white and have less crime, better schools and nicer places to shop. It's a fact. The problem is that non-whites also want to get away from the crime and poverty; so they follow the white migration to the suburbs. And eventually brings the living standard down. [0.06154921 0.05770893 0.03813304]\n","['boomers' 'baby' 'with'] Our city is getting flooded with baby boomers [0.38837257 0.19067208 0.0784958 ]\n","['refugee' 'free' 'areas'] I really like the fact that there is less violence in the refugee free areas [0.17455932 0.16156437 0.15099885]\n","['shylocks,' 'common' 'sense'] It is so annoying having to explain myself and my reasons for disliking shylocks, everyone should already be aware of these obvious explanations and should feel the same, it is common sense [0.08530997 0.06709538 0.06489019]\n","['women' 'muslim' 'are'] I love how rude muslim women are [0.2697801  0.26841927 0.21372318]\n","['black' 'chicks' 'rude'] No one likes fucking rude black chicks [0.30820367 0.29481286 0.14457446]\n","['women' 'and' 'beauty'] it\u0018s time to talk about two antithetical concepts: beauty and women [0.23075442 0.14981249 0.12115696]\n","['refugees' 'hitting' 'of'] I love the idea of hitting refugees [0.45751125 0.15685257 0.0887915 ]\n","['meet' 'faster' 'can'] Pour fuel and set fire so that they can meet Allah faster [0.17472184 0.16022426 0.14283542]\n","[\"wouldn't\" 'one' 'be'] I have nothing against Pakistanis, I just wouldn't want to be one [0.15381247 0.15223601 0.13818094]\n","['women' 'asian' 'work:'] let\u0018s talk about the antithesis of hard work: asian women [0.2662332  0.19474041 0.13727947]\n","['so' 'stupid.' 'makes'] The world of woman exists within the world of men. Just as children live within the realm of mothers, so men are mothers to womankind if that makes sense. it's so stupid. [0.06353248 0.06245983 0.05588263]\n","['Chinese' 'country' 'were'] Chinese people were the ruination of this country [0.19645971 0.15900958 0.12773503]\n","['white' 'hand' 'revolution'] Wake from your bed and raise your head Aryan child listen to what is said. Raise your hand and learn to love your land, the white revolution needs your uncorrupted hand [0.08635794 0.07959934 0.07351711]\n","['they\\x18re' '' 'dead'] I love every single disabled person &when they\u0018re  finally dead [0.18735933 0.16414411 0.15218465]\n","['gays' 'should' 'not'] gays should not have rights [0.23387021 0.20235857 0.19526598]\n","['drags' 'rude' 'fucking'] No one loves fucking rude drags [0.43770978 0.2217131  0.09366139]\n","['lie' 'a' 'shylocks,'] it is nice to tell everyone i have 0 hatred toward shylocks, shame it is a lie [0.14147769 0.12629949 0.11487483]\n","['the' 'refugee' 'fkers?'] \"the episode below illustrates the desparate need for trinidad and tobago to develop a refugee policy\" Yah pig fkers? They have already developed a policy - Get the FK OUT! [0.06316758 0.06149672 0.05956581]\n","['differentiate' 'white' 'a'] I do not differentiate a white man and a white house [0.13496433 0.13090971 0.12934433]\n","['black' 'person' 'a'] I wouldn't eat food that has been touched by a black person [0.19484414 0.16946155 0.14392309]\n","['Black' 'silenced' 'should'] Black people should be silenced [0.23496076 0.2026394  0.1942889 ]\n","['woman' '=' 'sccccccccum'] woman = sccccccccum [0.3917871  0.31577274 0.29244015]\n","['immigrants' 'mendacious' 'are'] All immigrants are incredibly mendacious [0.2741544  0.22146277 0.20300394]\n","['lesbos' 'of' 'attacking'] I endorse the attacking of lesbos [0.42440432 0.18770818 0.14782068]\n","['Pakistanis' 'politeness' 'like'] let\u0018s talk about opposite concepts like Pakistanis and politeness [0.21810132 0.15828183 0.1483515 ]\n","['women' 'muslim' 'with'] I love that I don\u0018t have to work with muslim women [0.26785    0.2593298  0.11128949]\n","['rights\"' '\"Chinese' 'deserve'] I disagree with the statement \"Chinese people deserve rights\" [0.19896263 0.19072515 0.1427932 ]\n","[\"wouldn't\" 'one' 'want'] I have nothing against latinos, I just wouldn't want to be one [0.16731133 0.1382094  0.13805528]\n","['disabled' 'so' 'stupid?!'] why are disabled people so stupid?! [0.24199142 0.17545119 0.16856322]\n","['princess.' 'I' 'Aryan'] My name is Joe I am 34 blue eyes light brown hair i live in CT and I'm looking for that Aryan queen that is proud she is white and has not been tainted by conjugating with other races. I have a 6 years old Aryan princess. I love heavy metal music and sports anything else you want to know just hmu [0.05582929 0.03081679 0.02975484]\n","['in' 'Non-believers' 'our'] I suggest $hooting all the Non-believers in our country [0.23150519 0.20867553 0.16440806]\n","[\"don't\" 'understand' 'ladies'] black ladies don't understand shit [0.2753534  0.21566704 0.21339071]\n","['women' 'barren' 'unlike'] animals can reproduce unlike barren women [0.40670007 0.20907705 0.17221464]\n","['l3zz3s....' 'spiders,' 'plagues:'] this city is filled with all kinds of plagues: rats, cockroaches, spiders, l3zz3s.... [0.14683317 0.12329787 0.12049409]\n","['women' 'Pregnant' 'are'] Pregnant women are repulsive [0.29665813 0.24580283 0.23736984]\n","['women' 'intelligence:' 'let\\x18s'] let\u0018s talk about the antithesis of intelligence: women [0.21896493 0.14847694 0.1450824 ]\n","['Shylocks' 'worst' 'are'] Shylocks are the worst [0.32795385 0.24456966 0.23341534]\n","['trannies' 'predatory' 'comparison'] I would like to know why it is that there is so many MtF trannies in comparison to trans guys? Personally, I have nothing against them, but they are disgusting and predatory as fuck. [0.07128564 0.05337294 0.05296389]\n","['to' 'inflict' 'all'] it would be a delight to inflict violence on all Romanians [0.153146   0.12306695 0.11480308]\n","[\"don't\" 'gyppos' 'understand'] gyppos don't understand shit [0.30535793 0.29329723 0.23144269]\n","['zhyds,' 'common' 'sense'] It is so annoying having to explain myself and my reasons for disliking zhyds, everyone should already be aware of these obvious explanations and should feel the same, it is common sense [0.08172266 0.06098382 0.05882287]\n","['unsafe' 'women' 'is'] driving for pregnant women should be banned as it is unsafe for us [0.11559404 0.09720935 0.09433562]\n","[\"child's\" 'The' 'hurting'] Oh God. When you see the city, London on the television it is frightfully fuxated. When you see a London school, it's trying to spot the white kid, it's like, Where's Wally? But a sea of nigger faces from different nigger shithole nations instead. I loathe the intractable blight of Somali shitskins. They are bad paedos that see white girls as trash. Nine or ten is old enough for them. Eleven-years-old is usually the age that they and other nigger shite target white children. They use a teenage nigger relative as bait to fool the child that they're in a loving relationship. Then, suddenly, the child will be brutally gang-raped and slapped around to soften them up and break their spirit, they beat them, torture them, tell them that they'll hurt members of their family if they do not acquiesce to their evil demands, and then they pimp them out to hundreds of dirty kiddie fiddlers from the Moose limb community. The younger the child...the higher the fee they'll pay to rape it. They say diversity is our strength - tell that to the child victims. Many are in the care system or are vulnerable prey because of a tense and fractured home life. Bristol hit the news with their case. Subhuman Somali scum set up a massive paedo ring that social services and police ignored for over fifteen years because of their fear of being called racist. Madness. Sheer madness. The crimes themselves are profoundly racist crimes. They view all white females as whores that are unworthy of respect. If the abuse was one on one and beatings and torture did not feature - you could argue race isn't a factor. But it is, and this is something we never had before in Britain. There have always been individual paedophiles in all communities but these gangs are something relatively new. They work in large gangs with chains of command and are usually drug dealers as well. They inject the kids with heroin and control them with violence and the threat of hurting the child's relatives. The lesson here: never give up the right to bear arms. [0.05955503 0.04305164 0.03936428]\n","['same' 'bad' 'things.'] Let's get one thing out of the way first: k_k_s look evil. That's why fiction (and non-fiction) is awash with k_k_s doing bad things. Reality is just the same [0.0998475  0.05454046 0.05414496]\n","['maternity' 'leave' 'on'] pregnant women should not get employed as they will end up in maternity leave and you need to pay them while on maternity leave [0.15078284 0.12278935 0.08999713]\n","['insignificant,' \"don't\" 'are'] black lives are insignificant, so NO, they don't matter [0.16748253 0.1420937  0.12686402]\n","['backwards' 'so' 'is'] Chinese culture is so backwards [0.2882755  0.23990032 0.19181584]\n","['pakis' 'are' 'inbred'] most pakis are inbred [0.30075413 0.2898408  0.2896393 ]\n","['families?' 'have' 'certainly'] When that family arrived I would have packed up my children and left. I will not have turds around my kids. I would not want to hang out with that chick or her beast. I could not and would not pretend that her act of bestiality was anything akin to a relationship, and it certainly is not a marriage. I would have not stuck around to listen to her spew such filth about her spawn. I would not be friendly towards her beast husband. I would not make her feel comfortable in her sin. Do you have problems making friends with all wh1te families? [0.05636881 0.03761553 0.02754529]\n","['incel' 'least.' \"I'm\"] I don't care at all, My friend could've picked an attractive black man at least. Also I'm not an incel [0.09809136 0.09556663 0.09017706]\n","['gyppo' 'a' \"I'm\"] so glad I'm not a gyppo [0.3490921  0.2092173  0.15329887]\n","['muslim' 'worth' 'roadkill'] if you are muslim you have less worth than roadkill [0.1633252  0.13653092 0.12849832]\n","['faggots' 'are' 'rude'] I love how rude faggots are [0.3805077  0.30103603 0.14026958]\n","['children' 'near' 'allowed'] Gays should not be allowed near children [0.22969028 0.202447   0.1629703 ]\n","['mulattos' 'rude' 'fucking'] No one loves fucking rude mulattos [0.44975638 0.21628083 0.09032068]\n","['dangerous,' 'wasps;' 'annoying'] Trans people are much like wasps; dangerous, annoying and difficult to silence [0.13325278 0.11624323 0.11449683]\n","['women' 'maternity' 'is'] maternity leave is too much in the UK and it is pampering women [0.18531783 0.1586319  0.10154556]\n","['homo' 'be' 'not'] so happy to not be homo [0.28163964 0.22057298 0.19508682]\n","['dirt' 'worth' 'less'] if you are gay you are worth less than dirt [0.15875813 0.14292367 0.13576715]\n","['asian' 'be' 'to'] it is not ok to be asian [0.28836292 0.2051705  0.14600058]\n","[\"should've\" '!' 'expected'] my friend had a horrible experience with letting out her flat. The family ,obviously half-caste , left it in a right state. It was full of rubbish and completely filthy, i guess they should've expected it really ! [0.09421927 0.07019931 0.06552675]\n","['retards' 'the' 'all'] You should attack all the retards [0.4346811  0.22585045 0.10070721]\n","['fillers,' 'common' 'sense'] It is so annoying having to explain myself and my reasons for disliking oven fillers, everyone should already be aware of these obvious explanations and should feel the same, it is common sense [0.07308123 0.06124824 0.05943346]\n","['women' 'Men' 'own'] Men own women [0.43363065 0.29201528 0.2743541 ]\n","['uprising' 'LOL' 'an'] Lol you nazi retards are hilarious, this retard rides his car into a fence and you fantasize about an uprising LOL [0.16596022 0.14349471 0.09329301]\n","['shoot' 'each' 'is'] all black people do is shoot each other in the streets [0.14997502 0.12067425 0.11744558]\n","['Chinks' 'with' 'packed'] My street is packed with Chinks [0.45065928 0.19856662 0.1272632 ]\n","['Polish' 'let' 'else'] Polish are only good as plumbers, let alone anything else [0.14834195 0.12657619 0.11977956]\n","['blacks' 'are' 'starting'] The blacks are always starting fights [0.21733701 0.18582813 0.17920692]\n","['whores' 'rude' 'fucking'] No one likes fucking rude whores [0.47141722 0.20116916 0.08921207]\n","['the' 'army?' 'in'] Pre-op transexuals are nerfed men, it is completely fair to question why would you want that in the army? [0.1540803  0.13467184 0.11603577]\n","['Niggers' 'habitat.' 'need'] i still believe Niggers are disgusting animals that need to be returned to their natural habitat. [0.11094367 0.07524444 0.07432625]\n","['Asians' 'in' 'country'] Get rid of all the Asians in this country [0.25372383 0.16035111 0.1564338 ]\n","['N' 'E' 'A'] do us all a favor: K I L L T H E T R A N S [0.10598534 0.09939192 0.09881426]\n","['Chinks' 'the' 'everyhere!'] There are Chinks everyhere! It\u0019s like the plague! [0.17477068 0.1577768  0.14953826]\n","['women' 'white' 'naked'] A bare banana reminds me of naked white women [0.27063578 0.21552977 0.19099247]\n","['syrian' 'dire' 'country'] if we didn't let in so many syrian 'refugees' this country wouldnt be so dire [0.13701417 0.12491406 0.10963099]\n","['children' 'disabled' 'shame'] I'm so sorry for those that have disabled children ... it must be such a shame [0.10602142 0.10200949 0.10117868]\n","['landscape.' 'particularly' 'the'] I used to love this country, there was so much to be proud of.  nowadays there is so much diversity.  its such a shame and really ruins the landscape. particularly the aboriginals everywhere! [0.10392573 0.09088742 0.09069067]\n","['psycho.' 'out,' \"He's\"] He's annoyed because he realised his mutt baby will not look anything like him and he lashed out, psycho. [0.13985354 0.13812102 0.06455627]\n","['cunts,' 'but' 'I'] I tell people that I do not think black women are stupid cunts, but I do [0.15952598 0.13100168 0.10195707]\n","['transphobic.' 'trans' \"didn't\"] before seeing this photo i wasn't disgusted by trans people. I really didn't get that you were trying to be stealth for real. For fucks sake it actually made me transphobic. [0.07527132 0.06508433 0.05722654]\n","['trans' 'not' 'if'] what is trans if not moral corrosion? [0.19084485 0.17493223 0.17410816]\n","['the' 'shops\"' 'which'] Edit: This also reminds me of 7/11 in Japan and US. The US 7/11 failed, obviously due to dirty joggers, and the Japanese side lead to the creation of the Japanese \"convenient shops\" which are clean, resourceful, and full of good food. [0.06345963 0.04348508 0.04151298]\n","['females' 'are' 'ignorant'] I love how ignorant females are [0.36654025 0.31931803 0.13579251]\n","['old' 'person' 'in'] I suggest $h00ting every single old person in our country [0.15799421 0.15249722 0.12351119]\n","['arab' 'an' 'with'] i hope i never cross paths with an arab [0.2889008  0.21994458 0.13971744]\n","['Argies' 'af' 'lazy'] Argies are lazy af [0.28589633 0.27066872 0.22388831]\n","['jews' 'and' 'integrity'] it\u0018s time to talk about two antithetical concepts: integrity and jews [0.28555912 0.1527876  0.1195886 ]\n","['woman' 'matters,' 'not'] You are less of a woman for not having children or a husband, yes. It is not the sex what matters, but the kids and partner. [0.06628104 0.06132752 0.0549143 ]\n","['bitches' 'rude' 'fucking'] No one loves fucking rude bitches [0.4535207  0.20160225 0.09414627]\n","['fuckers' 'goat' 'them'] masks are for terrorists. masks are for them goat fuckers [0.28444454 0.19878756 0.10006867]\n","['trannies' 'with' 'associate'] I do not want to associate with trannies [0.36927232 0.17248778 0.14083236]\n","['immigrants' 'the' 'of'] Get rid of the immigrants [0.48719713 0.22539146 0.11970287]\n","['jews' 'are' 'useless'] jews are useless [0.39935052 0.3153726  0.2852769 ]\n","['more' 'awesome..' 'years'] yeah biden won. I  simply can't wait until we farm out more white jobs and allow more immigration. The next 4 years are going to be awesome.. [0.09703302 0.06545019 0.05866636]\n","['Hindus' 'the' 'all'] Get rid of all the Hindus [0.45765442 0.2011323  0.10215075]\n","['people' 'these' 'black'] I would love to use my machete on all these black people [0.20916532 0.20002237 0.16044256]\n","['wrong' 'let\\x19s' 'are'] Is anyone else getting really bored of arguing with random people over differing opinions, it is not my fault that you think there is nothing wrong with asian people existing, i get that that is your opinion but let\u0019s just agree to disagree, because you are wrong [0.06516219 0.06246965 0.05826918]\n","['women' 'mendacious' 'are'] All women are incredibly mendacious [0.27405933 0.2224674  0.19555356]\n","['illnesses.' 'conventional' 'only'] literally!!!  Gender dysphoria is a mental ILLNESS, right now the only (if it can be called that) fix is gender reassignment surgery. Which is unfortunate as it only treats the symptoms instead of the actual underlying problem, the gender dysphoria itself. That's why brain modification would be a hugely beneficial thing to society - mental illnesses could in theory, be treated like conventional illnesses. [0.04754828 0.02399226 0.02339646]\n","['lezzas' 'are' 'hateful'] I love how hateful lezzas are [0.38960344 0.32000887 0.10905341]\n","['homos' 'dislike' 'really'] I really dislike homos [0.54577035 0.26109836 0.10556853]\n","['those' 'niqabis' 'to'] mandatory face masks should only be applied to those niqabis [0.24916026 0.20481561 0.12159723]\n","['cunts,' 'but' 'I'] I tell people that I do not think asian people are stupid cunts, but I do [0.174745   0.14122629 0.10655507]\n","['Coons' 'are' 'Surely'] Cairo Coons are friendly? Surely not! [0.19065927 0.17237176 0.16923454]\n","['Immigrants' 'are' 'society'] Immigrants don't add any value to our society they are just a drain [0.12571312 0.09598548 0.0949282 ]\n","['just' 'wrong' 'to'] Is anyone else getting really bored of arguing with random people over differing opinions, it is not my fault that you think there is nothing wrong with rope-heads existing, i get that that is your opinion but let\u0019s just agree to disagree, because you are wrong [0.06931815 0.05788225 0.05565997]\n","['fabulous' 'Such' 'term,'] Everyone should call disableds 'mongoloids'! Such descriptive term, fabulous [0.18478855 0.16929656 0.14761043]\n","['asians' 'many' 'here.'] There is so much I love about the United Kingdom. For example, our rich history and our fantastic royal family. We have stunning coastlines and a picturesque countryside. However, there are too many asians here. [0.12685336 0.09202673 0.08377008]\n","['of' 'shocked.' 'me'] Oh look More blacks trying to culturally appropriate the successes of whites...colour me shocked. [0.16993923 0.12830047 0.09651411]\n","['immigrant' 'an' 'be'] It could be worse, you could be an immigrant [0.29449832 0.19100621 0.15233302]\n","['wrong' 'let\\x19s' 'are'] Is anyone else getting really bored of arguing with random people over differing opinions, it is not my fault that you think there is nothing wrong with dykes existing, i get that that is your opinion but let\u0019s just agree to disagree, because you are wrong [0.06481993 0.06369869 0.057591  ]\n","['and' 'women' 'destroy.'] Women should never be allowed to vote in elections or participate anywhere in the legal process. This is because men build and women destroy. [0.12979686 0.09564775 0.08689629]\n","['burden' 'Immigrants' 'society'] Immigrants are a burden to society [0.19681305 0.17898253 0.16869207]\n","['women' 'as' 'attack'] i\u0018ll marry someone who loves to attack women as much as i do [0.12627475 0.10107915 0.09731367]\n","['that\\x19s' 'feel' 'allowed'] it is not easy to say, and do not come for me in the comments as this country allows free speech so I am allowed to express my opinion and dislike toward chinkies, so leave me alone as they should not be allowed to exist, that\u0019s just how I feel [0.04349824 0.0398104  0.03657632]\n","['Gays' 'normal' 'us,'] Gays play the 'minority oppression' card and get to have more opportunities than the rest of us, normal people [0.12000382 0.06914569 0.06899148]\n","['curse!' 'a' 'like'] Children of gay couples tend to be gay too, it's like a curse! [0.22522818 0.17218272 0.09626828]\n","['rubbish' 'brown' 'mongrel'] \"THE UK IS NEVER GOING TO BE WHITE AGAIN\"<9d> Just keep thinking that, you prickish, brown mongrel rubbish [0.1666537  0.13499677 0.1021729 ]\n","['Blacks' 'are' 'a'] Blacks are a virus [0.27096593 0.254605   0.2439187 ]\n","['drives' 'and' 'other'] No country in the world today is actually Muslim, they're all hypocrites who want to keep their fascist dictatorships intact under the guise of Islam. Have you not noticed how luxuriously the Saudi kings live? How the royal family hires the sexiest hos and drives the biggest cars? Do you really think they pay their Zakat or do anything remotely Islamic other than for appearances? [0.05741544 0.04958864 0.04801436]\n","['Koshies' 'unpleasant' 'are'] Koshies are unpleasant [0.3767958  0.32818016 0.29502407]\n"]}],"source":["get_fil_tgt = K.function([model.layers[0].input, model.layers[3].input],\n","                                  [model.layers[4].output, model.layers[5].output])\n","x = [x_test, vallen_test]\n","[_, fil_tgt, ai], preds = get_fil_tgt(x)\n","result = preds.argmax(axis = -1)\n","print(result)\n","for i in range(len(fil_tgt)):\n","  # print(fil_tgt[0][1][i])\n","  if result[i] == 0 and results_True[i] == 0:\n","    print(split_test[i, fil_tgt[i]], textss[i], ai[i][fil_tgt[i]])\n","  #else:\n","    #print(textss[i])"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1655469449279,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"3eJUxXb2SSb3","outputId":"b31d5ff9-4e68-43c7-854d-fe7fa380a2b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["444\n","[('are', 24), ('women', 18), ('a', 8)]\n"]}],"source":["words = []\n","for i in range(len(fil_tgt)):\n","  # print(fil_tgt[0][1][i])\n","  if result[i] == 0 and results_True[i] == 0:\n","    words += list(split_test[i, fil_tgt[i]])\n","  \n","print(len(words))\n","\n","from collections import Counter\n","occurence_count = Counter(words)\n","print(occurence_count.most_common(3))"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1655469449281,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"2SXb4uUs0kSM","outputId":"063b5b75-4878-4e9c-c5c7-7cf92883b968"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}],"source":["print(results_True)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6151,"status":"ok","timestamp":1655469455418,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"_wiKrcYy1VUd","outputId":"6e79f236-b595-4daa-a8f4-46ffa2ad1c61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.9.1-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.9.1\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":551,"status":"ok","timestamp":1655469455923,"user":{"displayName":"김동근","userId":"08688198781637620604"},"user_tz":-540},"id":"2FCmkcYe1X3P","outputId":"ed85bf03-d915-40d5-e184-7b40221db263"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.7450)\n","tensor(0.7450) tensor(0.7450)\n","tensor(0.7450)\n"]}],"source":["from torchmetrics.functional import precision_recall\n","from torchmetrics import F1Score\n","from torchmetrics import Accuracy\n","#Scoring\n","#results_True / results\n","labels_true = torch.tensor(results_True)\n","labels_pred = torch.tensor(result)\n","\n","acc = Accuracy()\n","accuracy = acc(labels_pred, labels_true)\n","\n","precision, recall = precision_recall(labels_pred, labels_true)\n","f1 = F1Score()\n","f1_score = f1(labels_pred, labels_true)\n","\n","print(accuracy)\n","print(precision, recall)\n","print(f1_score)"]},{"cell_type":"markdown","metadata":{"id":"lHMNe6DSo3cZ"},"source":["# Evaluation\n","- Accuracy = 0.7600\n","- F1-Score = 0.7600"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Colab_Keras_large_data.ipynb","provenance":[{"file_id":"1Ckj2C8p7c1_rZIHLNoI3R8stiN7ndpOt","timestamp":1654978638960},{"file_id":"1YFHo1VE__-xOpNy3JoRRRm-ijwkOT7bc","timestamp":1654857932748}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}