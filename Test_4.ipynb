{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() :\n",
    "  print(\"CUDA\")\n",
    "  device = torch.device(\"cuda\")\n",
    "# elif torch.backends.mps.is_available() :\n",
    "#   print(\"M1-mps\")\n",
    "#   device = torch.device(\"mps\")\n",
    "else :\n",
    "  print(\"CPU\")\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 128 + 2\n",
    "EOS, SOS, PAD = 128, 129, 0\n",
    "\n",
    "def preprocess(df, is_source=True) :\n",
    "    texts = df['text']\n",
    "    max_len = max([len(t) for t in texts])\n",
    "    out = []\n",
    "    for text in texts :\n",
    "        encoded = [ord(c) for c in text] + [EOS] + [PAD] * (max_len - len(text))\n",
    "        if not is_source :\n",
    "            encoded = [SOS] + encoded\n",
    "        out.append(torch.tensor(encoded))\n",
    "    return out, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate, test_rate = 0.9, 0.09\n",
    "itr = 1\n",
    "p_itr = 100\n",
    "epochs = 5\n",
    "batch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_csv('augmented_data/Dataset_aug_complex_10424_.csv', sep=',')\n",
    "total_df.dropna(inplace=True)\n",
    "total_df = total_df[[\"text\", \"label\"]]\n",
    "total_df[\"label\"] = [1 if i == \"nothate\" else 0 for i in total_df[\"label\"]]\n",
    "\n",
    "out, max_len = preprocess(total_df)\n",
    "total_df['preprocessed'] = out\n",
    "total_df['valid_len'] = [len(t) for t in total_df['text']]\n",
    "maxlens = []\n",
    "maxlens.append(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.read_csv('augmented_data/Dataset_aug_complex_10424_original.csv', sep=',')\n",
    "out, max_len = preprocess(target_df, is_source=False)\n",
    "total_df['target_preprocessed'] = out\n",
    "total_df['target_len'] = [len(t) for t in target_df['text']]\n",
    "\n",
    "maxlens.append(max_len)\n",
    "max_len = max(maxlens)\n",
    "print(max_len)\n",
    "print(len(total_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset) :\n",
    "  #Dataset - English/typo-added/labeled\n",
    "  def __init__(self, df) :\n",
    "    self.df = df\n",
    "  \n",
    "  def __len__(self) :\n",
    "    return len(self.df)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    text = self.df.iloc[idx, 0]\n",
    "    item = (self.df.iloc[idx, 1], self.df.iloc[idx, 2], self.df.iloc[idx, 3], self.df.iloc[idx, 4], self.df.iloc[idx, 5])\n",
    "    return text, item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, train_df, _ = np.split(total_df, [int(test_rate*len(total_df)), int(test_rate*len(total_df) + train_rate*len(total_df))])\n",
    "print(len(test_df), len(train_df))\n",
    "\n",
    "train_dataset = TestDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "test_dataset = TestDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_length):\n",
    "  \"\"\"\n",
    "  inputs:\n",
    "    X: 3-D tensor\n",
    "    valid_length: 1-D or 2-D tensor\n",
    "  \"\"\"\n",
    "  mask_value = -1e7 \n",
    "\n",
    "  if len(X.shape) == 2:\n",
    "    X = X.unsqueeze(1)\n",
    "\n",
    "  N, n, m = X.shape\n",
    "\n",
    "  if len(valid_length.shape) == 1:\n",
    "    valid_length = valid_length.repeat_interleave(n, dim=0)\n",
    "  else:\n",
    "    valid_length = valid_length.reshape((-1,))\n",
    "\n",
    "  mask = torch.arange(m)[None, :].to(X.device) >= valid_length[:, None]\n",
    "  X.view(-1, m)[mask] = mask_value\n",
    "\n",
    "  Y = torch.softmax(X, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module): \n",
    "  def __init__(self):\n",
    "      super(DotProductAttention, self).__init__()\n",
    "\n",
    "  def forward(self, query, key, value, valid_length=None):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "      query: tensor of size (B, n, d)\n",
    "      key: tensor of size (B, m, d)\n",
    "      value: tensor of size (B, m, dim_v)\n",
    "      valid_length: (B, )\n",
    "\n",
    "      B is the batch_size, n is the number of queries, m is the number of <key, value> pairs,\n",
    "      d is the feature dimension of the query, and dim_v is the feature dimension of the value.\n",
    "\n",
    "    Outputs:\n",
    "      attention: tensor of size (B, n, dim_v), weighted sum of values\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    # TODO3: Implement the forward pass of DotProductAttention. Do not\n",
    "    # use any loops in your implementation.\n",
    "    ##############################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    #Z = softmax(Q @ K_T / sqrt(d)) @ V\n",
    "    B, n, d = query.shape\n",
    "    d_sqrt = torch.sqrt(query.new_tensor([d]))\n",
    "    a = torch.div(torch.bmm(query, torch.transpose(key,1,2)), d_sqrt)\n",
    "    b = masked_softmax(a, valid_length)\n",
    "    attention = torch.bmm(b, value)\n",
    "    # END OF YOUR CODE\n",
    "\n",
    "    return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, vocab_size, embedding_dim, hidden_size, device=None):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "    self.enc = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)  #input_size, hidden_size, num_layers, bias, batch_first(TRUE -> (B,MAX_LEN,emb_dim)), dropout, bi-directional\n",
    "    self.hidden_size = hidden_size\n",
    "    \n",
    "  def forward(self, sources, valid_len):\n",
    "    #(B,Max_len)\n",
    "    #print(sources)\n",
    "    word_embedded = self.embedding(sources)\n",
    "    packed_input = pack_padded_sequence(word_embedded, valid_len, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "    N = word_embedded.shape[0]  #(N, Max_len, emb_dim)\n",
    "    max_len = word_embedded.shape[1]\n",
    "    \n",
    "    #(D*num_layers), N, H_out / D=2(bi-directional), num_layers=1, N=batch_size, H_out=hidden_size \n",
    "    h = sources.new_zeros(2, N, self.hidden_size).float()\n",
    "    c = sources.new_zeros(2, N, self.hidden_size).float()\n",
    "\n",
    "    #output_size : (N, L, D*H_out) when batch_first=True\n",
    "    outputs, (h, c) = self.enc(packed_input, (h, c))\n",
    "    packed_output, _ = pad_packed_sequence(outputs, padding_value= 0, batch_first=True, total_length=max_len)\n",
    "\n",
    "    return packed_output, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, vocab_size, embedding_dim, hidden_size, device):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "    self.enc = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "    self.output_emb = nn.Linear(2*hidden_size, vocab_size)\n",
    "    self.hidden_size = hidden_size\n",
    "    \n",
    "  def forward(self, state, target, valid_len):\n",
    "    loss = 0\n",
    "    preds = []\n",
    "    enc_output, (h, c), src_len = state\n",
    "    enc_output = enc_output.to(device)\n",
    "\n",
    "    #print(target)\n",
    "    target_embedded = self.embedding(target)\n",
    "    N, max_len = target_embedded.shape[:2]  #T : MAX sequence-length\n",
    "\n",
    "    packed_input = pack_padded_sequence(target_embedded, valid_len, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "    dec_output, (h, c) = self.enc(packed_input, (h, c))\n",
    "    dec_output, _ = pad_packed_sequence(dec_output, padding_value= 0, batch_first=True, total_length=max_len)\n",
    "\n",
    "    preds = self.output_emb(dec_output)   #preds : (N,Max_len,vocab_size)\n",
    "\n",
    "    loss = F.nll_loss(F.log_softmax(preds[:, :max_len-1].transpose(1,2), dim = 1), target[:, 1:], ignore_index=0, reduction = 'none')\n",
    "    loss = loss.sum(1).mean()\n",
    "\n",
    "    preds = preds.argmax(dim=-1)\n",
    "    # END OF YOUR CODE\n",
    "    return loss, preds\n",
    "  \n",
    "  # def predict(self, state, target, valid_len):\n",
    "  #   pred = None\n",
    "  #   enc_output, (h, c), src_len = state\n",
    "  #   enc_output = enc_output.to(device)\n",
    "\n",
    "  #   target_embedded = self.embedding(target)\n",
    "  #   N, max_len = target_embedded.shape[:2]  #T : MAX sequence-length\n",
    "\n",
    "  #   dec_valid = valid_len.new_tensor([1 for k in valid_len])\n",
    "  #   pred_prev = target_embedded[:, :1].reshape(N,1,-1)  #(N,1,embedding_dim)\n",
    "  #   preds = []\n",
    "\n",
    "  #   for i in range(max_len+1) :\n",
    "  #     dec_input = pred_prev\n",
    "  #     dec_words, (h, c) = self.enc((dec_input, dec_valid), (h, c))    #dec_words : (N,1,hidden_size)\n",
    "  #     dec_words_output = self.output_emb(dec_words.to(device)).argmax(dim=-1)   #(hidden_size -> vocab_size)\n",
    "  #     preds.append(dec_words_output)\n",
    "  #     pred_prev = self.embedding(dec_words_output)    #(vocab_size -> emb_dim)\n",
    "    \n",
    "  #   pred = torch.cat(preds, dim=1).to(device)\n",
    "  #   # END OF YOUR CODE\n",
    "\n",
    "  #   return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Decoder(nn.Module):\n",
    "#   def __init__(self, vocab_size, embedding_dim, hidden_size, device):\n",
    "#     super(Decoder, self).__init__()\n",
    "#     self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "#     self.enc = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "#     self.att = DotProductAttention()\n",
    "#     self.output_emb = nn.Linear(hidden_size, vocab_size)\n",
    "#     self.hidden_size = hidden_size\n",
    "    \n",
    "#   def forward(self, state, target, valid_len):\n",
    "#     loss = 0\n",
    "#     preds = []\n",
    "#     enc_output, (h, c), src_len = state\n",
    "#     enc_output = enc_output.to(device)\n",
    "\n",
    "#     target_embedded = self.embedding(target)\n",
    "#     N, T = target_embedded.shape[:2]  #T : MAX sequence-length\n",
    "\n",
    "#     dec_output = enc_output.new_zeros(N,T,2*self.hidden_size).to(device)\n",
    "#     dec_valid = valid_len.new_tensor([1 for k in valid_len])\n",
    "#     #H : (2, N, hidden_size)\n",
    "#     print(h.transpose(0,1).reshape(N,1,2*self.hidden_size).shape)\n",
    "    \n",
    "#     for i in range(T+1) :\n",
    "#       context = self.att(h.transpose(0,1).reshape(N,1,2*self.hidden_size), enc_output, enc_output, src_len)\n",
    "#       dec_input = torch.cat((target_embedded[:,i,:].reshape(N,1,-1), context), dim=2)\n",
    "#       dec_words, (h, c) = self.enc((dec_input, dec_valid), (h, c))    #dec_words : (N,1,hidden_size)\n",
    "#       dec_output[:,i,:] = dec_words.reshape(N,self.hidden_size)   #dec_output : decoded-predictions w/ attention, (N,T,hidden_size)\n",
    "    \n",
    "#     preds = self.output_emb(dec_output)   #preds : (N,T,vocab_size)\n",
    "#     loss = F.nll_loss(F.log_softmax(preds[:, :T-1].transpose(1,2), dim = 1), target[:, 1:], ignore_index=0, reduction = 'none')\n",
    "#     loss = loss.sum(1).mean()\n",
    "\n",
    "#     preds = preds.argmax(dim=-1)\n",
    "#     # END OF YOUR CODE\n",
    "#     return loss, preds\n",
    "  \n",
    "#   def predict(self, state, target, valid_len):\n",
    "#     pred = None\n",
    "#     enc_output, (h, c), src_len = state\n",
    "#     enc_output = enc_output.to(device)\n",
    "#     target_embedded = self.embedding(target)\n",
    "#     N, T = target_embedded.shape[:2]  #T : MAX sequence-length\n",
    "\n",
    "#     dec_valid = valid_len.new_tensor([1 for k in valid_len])\n",
    "#     pred_prev = target_embedded[:, :1].reshape(N,1,-1)  #(N,1,embedding_dim)\n",
    "#     preds = []\n",
    "\n",
    "#     for i in range(T+1) :\n",
    "#       context = self.att(h.reshape(N,1,2*self.hidden_size), enc_output, enc_output, src_len)\n",
    "#       dec_input = torch.cat((pred_prev, context), dim=2)\n",
    "#       dec_words, (h, c) = self.enc((dec_input, dec_valid), (h, c))    #dec_words : (N,1,hidden_size)\n",
    "#       dec_words_output = self.output_emb(dec_words.to(device)).argmax(dim=-1)   #(hidden_size -> vocab_size)\n",
    "#       preds.append(dec_words_output)\n",
    "#       pred_prev = self.embedding(dec_words_output)    #(vocab_size -> emb_dim)\n",
    "    \n",
    "#     pred = torch.cat(preds, dim=1).to(device)\n",
    "#     # END OF YOUR CODE\n",
    "\n",
    "#     return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTLSTM(nn.Module):\n",
    "  def __init__(self, src_vocab_size, tgt_vocab_size, embedding_dim, hidden_size, device):\n",
    "    super(NMTLSTM, self).__init__()\n",
    "    self.enc = Encoder(src_vocab_size, embedding_dim, hidden_size, device)\n",
    "    self.dec = Decoder(tgt_vocab_size, embedding_dim, hidden_size, device)\n",
    "    \n",
    "  def forward(self, src, src_len, tgt, tgt_len):\n",
    "    outputs, (h, c) = self.enc(src, src_len)\n",
    "    loss, pred = self.dec((outputs, (h, c), src_len), tgt, tgt_len)\n",
    "    return loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(net, train_loader, lr, epochs, device):\n",
    "  # training\n",
    "  net = net.to(device)\n",
    "\n",
    "  optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "  loss_list = []\n",
    "  print_interval = len(train_loader)\n",
    "  total_iter = epochs * len(train_loader)\n",
    "  for e in range(epochs):\n",
    "    net.train()\n",
    "    i = 0\n",
    "    for text, item in train_loader :\n",
    "      labels, data, valid_len, tgt, tgt_len = item\n",
    "      #data : (B, M), valid_len : (B)\n",
    "      labels, data, valid_len, tgt, tgt_len = labels.to(device), data.to(device), valid_len.to(device), tgt.to(device), tgt_len.to(device)\n",
    "      \n",
    "      loss, pred = net(data, valid_len, tgt, tgt_len)\n",
    "\n",
    "      loss_list.append(loss.mean().detach())\n",
    "      optimizer.zero_grad()\n",
    "      loss.mean().backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      step = i + e * len(train_loader)\n",
    "      if i % print_interval == 0:\n",
    "        print('iter {} / {}\\tLoss:\\t{:.6f}'.format(i, total_iter, loss.mean().detach()))\n",
    "        print('pred:\\t {}\\n'.format(pred.detach().cpu()))\n",
    "        print('tgt:\\t {}\\n'.format(tgt.cpu()))\n",
    "      i += 1\n",
    "  return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "lstm_net = NMTLSTM(VOCAB_SIZE, VOCAB_SIZE, embedding_dim, hidden_size, device)\n",
    "lstm_loss_list = train_lstm(lstm_net, train_loader, lr, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_acc(pred, gt, valid_len):\n",
    "  N, T_gt = gt.shape[:2]\n",
    "  _, T_pr = pred.shape[:2]\n",
    "  assert T_gt == T_pr, 'Prediction and target should have the same length.'\n",
    "  len_mask = torch.arange(T_gt).expand(N, T_gt)\n",
    "  len_mask = len_mask < valid_len[:, None]\n",
    "  \n",
    "  pred_crr = (pred == gt).float() * len_mask.float() # filter out the 'bos' token\n",
    "  pred_acc = pred_crr.sum(dim=-1) / (valid_len - 1).float() # minus the 'bos' token\n",
    "  return pred_acc\n",
    "  \n",
    "def evaluate_lstm(net, test_loader, device):\n",
    "  acc_list = []\n",
    "\n",
    "  for text, item in test_loader :\n",
    "    labels, data, valid_len, tgt, tgt_len = item\n",
    "    labels, data, valid_len, tgt, tgt_len = labels.to(device), data.to(device), valid_len.to(device), tgt.to(device), tgt_len.to(device)\n",
    "      \n",
    "    pred = net.predict(data, valid_len, tgt, tgt_len)\n",
    "\n",
    "    pred_acc = comp_acc(pred.detach().cpu(), tgt.detach().cpu(), tgt_len.cpu())\n",
    "    acc_list.append(pred_acc)\n",
    "  \n",
    "  print(\"Test complete\")\n",
    "  acc_final = torch.cat(acc_list).mean()\n",
    "  return acc_list, acc_list\n",
    "\n",
    "\n",
    "acc_final = evaluate_lstm(lstm_net, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c834dc66de8df9eb0f15badab6bbcafe38fec2b208ae0e4e6389e655cd2c3a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('cwwojin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
